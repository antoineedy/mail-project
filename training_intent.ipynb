{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import functools\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from transformers import AutoModelForSequenceClassification, CamembertForMaskedLM, AutoTokenizer, AutoConfig\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing CamembertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/Users/antoineedy/Documents/Formation/mail-project/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "camembert = CamembertForMaskedLM.from_pretrained('camembert-base')\n",
    "tokenizer = AutoTokenizer.from_pretrained('camembert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sentences = [\n",
    "    \"Vous savez où est la <mask> la plus proche?\",\n",
    "    \"La Seine est un <mask>.\",\n",
    "    \"Je cherche urgemment un endroit où retirer de l'<mask>.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]),\n",
      " 'input_ids': tensor([[   5,  158, 2591,  ...,    1,    1,    1],\n",
      "        [   5,   61, 4458,  ...,    1,    1,    1],\n",
      "        [   5,  100, 1066,  ...,    1,    1,    1]])}\n"
     ]
    }
   ],
   "source": [
    "tokenizer_output = tokenizer(\n",
    "    batch_sentences,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "pprint(tokenizer_output, width=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>query</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>activite</td>\n",
       "      <td>Quelles activités proposez-vous pendant les va...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>activite</td>\n",
       "      <td>Avez-vous des cours de yoga à l'hôtel ?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>activite</td>\n",
       "      <td>Est-ce que vous proposez des sorties en voilier ?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>activite</td>\n",
       "      <td>Je voudrais savoir si vous avez des activités ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>activite</td>\n",
       "      <td>Y a-t-il des excursions organisées depuis l'hô...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                              query label_id\n",
       "0  activite  Quelles activités proposez-vous pendant les va...        0\n",
       "1  activite            Avez-vous des cours de yoga à l'hôtel ?        0\n",
       "2  activite  Est-ce que vous proposez des sorties en voilier ?        0\n",
       "3  activite  Je voudrais savoir si vous avez des activités ...        0\n",
       "4  activite  Y a-t-il des excursions organisées depuis l'hô...        0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_dataset_train = pd.DataFrame()\n",
    "\n",
    "# activite = 0\n",
    "# disponibilite_chambre = 1\n",
    "# ouverture_accueil = 2\n",
    "\n",
    "a = 0\n",
    "with open('test/test_data/queries_activite.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "for i in data:\n",
    "    pd_dataset_train[a] = [\"activite\", data[i], 0]\n",
    "    a +=1\n",
    "\n",
    "with open('test/test_data/queries_disponibilite_chambres.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "for i in data:\n",
    "    pd_dataset_train[a] = [\"disponibilite_chambre\", data[i], 1]\n",
    "    a +=1\n",
    "\n",
    "with open('test/test_data/queries_ouverture_accueil.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "for i in data:\n",
    "    pd_dataset_train[a] = [\"ouverture_accueil\", data[i], 2]\n",
    "    a +=1\n",
    "\n",
    "pd_dataset_train = pd_dataset_train.T\n",
    "pd_dataset_train.columns = ['label', 'query', 'label_id']\n",
    "\n",
    "pd_dataset_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>query</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>activite</td>\n",
       "      <td>Proposez-vous des sorties en bateau pour les c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>activite</td>\n",
       "      <td>Y a-t-il des cours de natation pour les enfants ?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>activite</td>\n",
       "      <td>Quels sont les tarifs pour louer des jets-skis...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>activite</td>\n",
       "      <td>L'hôtel propose-t-il des cours de plongée sous...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>activite</td>\n",
       "      <td>Est-ce qu'il y a des sorties organisées pour f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                              query label_id\n",
       "0  activite  Proposez-vous des sorties en bateau pour les c...        0\n",
       "1  activite  Y a-t-il des cours de natation pour les enfants ?        0\n",
       "2  activite  Quels sont les tarifs pour louer des jets-skis...        0\n",
       "3  activite  L'hôtel propose-t-il des cours de plongée sous...        0\n",
       "4  activite  Est-ce qu'il y a des sorties organisées pour f...        0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_dataset_test = pd.DataFrame()\n",
    "\n",
    "# activite = 0\n",
    "# disponibilite_chambre = 1\n",
    "# ouverture_accueil = 2\n",
    "\n",
    "a = 0\n",
    "with open('test/test_data/queries_activite_test.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "for i in data:\n",
    "    pd_dataset_test[a] = [\"activite\", data[i], 0]\n",
    "    a +=1\n",
    "\n",
    "with open('test/test_data/queries_disponibilite_chambres_test.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "for i in data:\n",
    "    pd_dataset_test[a] = [\"disponibilite_chambre\", data[i], 1]\n",
    "    a +=1\n",
    "\n",
    "with open('test/test_data/queries_ouverture_accueil_test.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "for i in data:\n",
    "    pd_dataset_test[a] = [\"ouverture_accueil\", data[i], 2]\n",
    "    a +=1\n",
    "\n",
    "pd_dataset_test = pd_dataset_test.T\n",
    "pd_dataset_test.columns = ['label', 'query', 'label_id']\n",
    "\n",
    "pd_dataset_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
       "       54, 55, 56, 57, 58, 59],\n",
       "      dtype='int64')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_dataset_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_batch(samples, tokenizer):\n",
    "    text = [sample[\"query\"] for sample in samples]\n",
    "    labels = torch.tensor([sample[\"label_id\"] for sample in samples])\n",
    "    str_labels = [sample[\"label\"] for sample in samples]\n",
    "    # The tokenizer handles\n",
    "    # - Tokenization (amazing right?)\n",
    "    # - Padding (adding empty tokens so that each example has the same length)\n",
    "    # - Truncation (cutting samples that are too long)\n",
    "    # - Special tokens (in CamemBERT, each sentence ends with a special token </s>)\n",
    "    # - Attention mask (a binary vector which tells the model which tokens to look at. For instance it will not compute anything if the token is a padding token)\n",
    "    tokens = tokenizer(text, padding=\"longest\", return_tensors=\"pt\")\n",
    "\n",
    "    return {\"input_ids\": tokens.input_ids, \"attention_mask\": tokens.attention_mask, \"labels\": labels, \"str_labels\": str_labels, \"sentences\": text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    5,  9827,    26,   315,   143,    20,  1310,    24,   116,  6092,\n",
       "             15,   350,     8,  1273,   106,     6,     1],\n",
       "         [    5, 19214,    26,   315,   103,   248,    86,    39,   441,   138,\n",
       "             20,   307,     8,  9475,   106,     6,     1],\n",
       "         [    5,  9827,    26,   315,    20,  1310,  1339,    24,    44,  1658,\n",
       "             26,   904,   106,     6,     1,     1,     1],\n",
       "         [    5,   468,  1262,  1507,  3402,    17,    11,  1585,  2385,   823,\n",
       "            106,     6,     1,     1,     1,     1,     1],\n",
       "         [    5,   121,    11,  2642,   737,     7,    15,  1262,  1507,  2033,\n",
       "             13,  2229,   106,     6,     1,     1,     1],\n",
       "         [    5,  1196,    26,   291,    27,    13,  2229,    30,  1995,   641,\n",
       "            133,  9571,   106,     6,     1,     1,     1],\n",
       "         [    5, 19214,    26,   315,   103,   248,   257,    11,   169,  1262,\n",
       "           1507,    13,  2229,    30,  1995,   106,     6],\n",
       "         [    5,    71,    11,  1843,  3916,    26,   110,    26,    62,    20,\n",
       "          11898,    47, 14720, 11764,    10,   106,     6]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
       " 'labels': tensor([1, 0, 1, 2, 2, 2, 2, 0]),\n",
       " 'str_labels': ['disponibilite_chambre',\n",
       "  'activite',\n",
       "  'disponibilite_chambre',\n",
       "  'ouverture_accueil',\n",
       "  'ouverture_accueil',\n",
       "  'ouverture_accueil',\n",
       "  'ouverture_accueil',\n",
       "  'activite'],\n",
       " 'sentences': ['Avez-vous encore des chambres pour deux nuits à partir de vendredi ?',\n",
       "  'Pouvez-vous me dire si vous proposez des cours de méditation ?',\n",
       "  'Avez-vous des chambres disponibles pour ce week-end ?',\n",
       "  \"À quelle heure ouvre l'accueil demain matin ?\",\n",
       "  \"J'arrive tard, à quelle heure ferme la réception ?\",\n",
       "  'Est-ce que la réception est ouverte 24h/24 ?',\n",
       "  \"Pouvez-vous me dire jusqu'à quelle heure la réception est ouverte ?\",\n",
       "  \"L'hôtel organise-t-il des randonnées ou balades guidées ?\"]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataloader = DataLoader(pd_dataset_test.to_dict(orient=\"records\"), batch_size=8, shuffle=True, collate_fn=functools.partial(tokenize_batch, tokenizer=tokenizer))\n",
    "val_dataloader = deepcopy(test_dataloader)\n",
    "train_dataloader = DataLoader(pd_dataset_train.to_dict(orient=\"records\"), batch_size=8, shuffle=True, collate_fn=functools.partial(tokenize_batch, tokenizer=tokenizer))\n",
    "next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57a84f56e8a540c096fbcf5460dd8630",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentences = []\n",
    "labels = []\n",
    "str_labels = []\n",
    "all_representations = torch.Tensor()\n",
    "\n",
    "def average_embeddings(embeddings, attention_mask):\n",
    "    return (attention_mask[..., None] * embeddings).mean(1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for tokenized_batch in tqdm(val_dataloader):\n",
    "        model_output = camembert(\n",
    "            input_ids = tokenized_batch[\"input_ids\"],\n",
    "            attention_mask = tokenized_batch[\"attention_mask\"],\n",
    "            output_hidden_states=True\n",
    "        )\n",
    "        batch_representations = average_embeddings(model_output[\"hidden_states\"][-1], tokenized_batch[\"attention_mask\"])\n",
    "        sentences.extend(tokenized_batch[\"sentences\"])\n",
    "        labels.extend(tokenized_batch[\"labels\"])\n",
    "        str_labels.extend(tokenized_batch[\"str_labels\"])\n",
    "        all_representations = torch.cat((all_representations, batch_representations), 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly",
        "staticPlot": true
       },
       "data": [
        {
         "hovertemplate": "color=activite<br>x=%{x}<br>y=%{y}<extra></extra>",
         "legendgroup": "activite",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "activite",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0.9954534,
          -0.12942907,
          0.6641417,
          -1.4718364,
          -1.2410978,
          -2.0086384,
          0.85634613,
          -0.90570194,
          -0.04652439,
          -1.9827961,
          1.7027395,
          -0.086605206,
          -1.6583321,
          2.1396782,
          -2.3815203,
          -0.2914234,
          -0.9002471,
          1.8913659,
          1.8424658,
          0.83733606
         ],
         "xaxis": "x",
         "y": [
          -0.7631644,
          1.1698881,
          0.31648803,
          0.07605771,
          1.8729099,
          -0.5508426,
          -0.35229486,
          2.0315878,
          0.87677306,
          -0.6086985,
          1.3244548,
          -0.374119,
          1.1353214,
          0.7087056,
          -0.38385424,
          0.41192788,
          0.937723,
          1.7028449,
          0.565583,
          0.6723391
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "color=disponibilite_chambre<br>x=%{x}<br>y=%{y}<extra></extra>",
         "legendgroup": "disponibilite_chambre",
         "marker": {
          "color": "#EF553B",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "disponibilite_chambre",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          2.0358343,
          3.4119587,
          2.3911061,
          1.9412194,
          2.6849282,
          3.9346693,
          3.4838855,
          2.6365716,
          2.568261,
          4.082855,
          3.4159462,
          1.9187372,
          3.0183403,
          3.086024,
          1.5981984,
          2.6051667,
          2.2359715,
          2.0028138,
          3.1203117,
          1.5533228
         ],
         "xaxis": "x",
         "y": [
          -2.7576199,
          -3.6943212,
          -2.9695303,
          -1.092886,
          -1.3810945,
          -2.5500793,
          -1.5787889,
          -2.090388,
          -0.90420514,
          -2.6792653,
          -2.3171332,
          -3.6359904,
          -2.030487,
          -3.3948584,
          -1.4129834,
          -3.3971963,
          -1.688122,
          -1.3817239,
          -0.9052723,
          -2.6517944
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "color=ouverture_accueil<br>x=%{x}<br>y=%{y}<extra></extra>",
         "legendgroup": "ouverture_accueil",
         "marker": {
          "color": "#00cc96",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "ouverture_accueil",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          -1.845082,
          -1.1072451,
          -0.8000911,
          -1.6172782,
          -1.4728323,
          -2.884203,
          -2.3400393,
          -1.9944164,
          0.15582187,
          -2.3859272,
          0.14303142,
          0.13306698,
          0.6380692,
          -0.23113197,
          -1.1884453,
          0.074288584,
          0.3005762,
          -1.0183787,
          -2.3946059,
          -0.031229671
         ],
         "xaxis": "x",
         "y": [
          -2.3352,
          -2.1427479,
          -1.931488,
          -2.896497,
          -1.2096317,
          -1.6092899,
          -2.2516632,
          -2.0058966,
          -4.0956836,
          -2.3781645,
          -1.9642138,
          -3.7795432,
          -1.8233163,
          -3.9821892,
          -1.3610159,
          -4.3239303,
          -1.8709671,
          -2.6525106,
          -2.7942004,
          -3.4915702
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "color"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "x"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "y"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE()\n",
    "all_representations_2d = tsne.fit_transform(all_representations.cpu())\n",
    "scatter_plot = px.scatter(x=all_representations_2d[:, 0], y=all_representations_2d[:, 1], color=str_labels)\n",
    "scatter_plot.show(config={'staticPlot': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de labels : 3\n"
     ]
    }
   ],
   "source": [
    "class LightningModel(pl.LightningModule):\n",
    "    def __init__(self, model_name, num_labels, lr, weight_decay, from_scratch=False):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        if from_scratch:\n",
    "            # Si `from_scratch` est vrai, on charge uniquement la config (nombre de couches, hidden size, etc.) et pas les poids du modèle\n",
    "            config = AutoConfig.from_pretrained(\n",
    "                model_name, num_labels=num_labels\n",
    "            )\n",
    "            self.model = AutoModelForSequenceClassification.from_config(config)\n",
    "        else:\n",
    "            # Cette méthode permet de télécharger le bon modèle pré-entraîné directement depuis le Hub de HuggingFace sur lequel sont stockés de nombreux modèles\n",
    "            self.model = AutoModelForSequenceClassification.from_pretrained(\n",
    "                model_name, num_labels=num_labels\n",
    "            )\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.num_labels = self.model.num_labels\n",
    "\n",
    "    def forward(self, batch):\n",
    "        return self.model(\n",
    "            input_ids=batch[\"input_ids\"],\n",
    "            attention_mask=batch[\"attention_mask\"]\n",
    "        )\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        out = self.forward(batch)\n",
    "\n",
    "        logits = out.logits\n",
    "        # -------- MASKED --------\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        loss = loss_fn(logits.view(-1, self.num_labels), batch[\"labels\"].view(-1))\n",
    "\n",
    "        # ------ END MASKED ------\n",
    "\n",
    "        self.log(\"train/loss\", loss)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_index):\n",
    "        labels = batch[\"labels\"]\n",
    "        out = self.forward(batch)\n",
    "\n",
    "        preds = torch.max(out.logits, -1).indices\n",
    "        # -------- MASKED --------\n",
    "        acc = (batch[\"labels\"] == preds).float().mean()\n",
    "        # ------ END MASKED ------\n",
    "        self.log(\"valid/acc\", acc)\n",
    "\n",
    "        f1 = f1_score(batch[\"labels\"].cpu().tolist(), preds.cpu().tolist(), average=\"macro\")\n",
    "        self.log(\"valid/f1\", f1)\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        \"\"\"La fonction predict step facilite la prédiction de données. Elle est\n",
    "        similaire à `validation_step`, sans le calcul des métriques.\n",
    "        \"\"\"\n",
    "        out = self.forward(batch)\n",
    "\n",
    "        return torch.max(out.logits, -1).indices\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(\n",
    "            self.model.parameters(), lr=self.lr, weight_decay=self.weight_decay\n",
    "        )\n",
    "\n",
    "num_labels = pd_dataset_train[\"label\"].nunique()\n",
    "print(f\"Nombre de labels : {num_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "lightning_model = LightningModel(\"camembert-base\", num_labels, lr=3e-5, weight_decay=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6e2f7aa7f487e79c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6e2f7aa7f487e79c\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = pl.callbacks.ModelCheckpoint(monitor=\"valid/acc\", mode=\"max\")\n",
    "\n",
    "camembert_trainer = pl.Trainer(\n",
    "    max_epochs=20,\n",
    "    # gpus=1,\n",
    "    callbacks=[\n",
    "        pl.callbacks.EarlyStopping(monitor=\"valid/acc\", patience=4, mode=\"max\"),\n",
    "        model_checkpoint,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type                               | Params | Mode\n",
      "--------------------------------------------------------------------\n",
      "0 | model | CamembertForSequenceClassification | 110 M  | eval\n",
      "--------------------------------------------------------------------\n",
      "110 M     Trainable params\n",
      "0         Non-trainable params\n",
      "110 M     Total params\n",
      "442.497   Total estimated model params size (MB)\n",
      "0         Modules in train mode\n",
      "230       Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72308f416e9b4666a251864df4593a52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antoineedy/Documents/Formation/mail-project/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:475: PossibleUserWarning:\n",
      "\n",
      "Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "\n",
      "/Users/antoineedy/Documents/Formation/mail-project/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: PossibleUserWarning:\n",
      "\n",
      "The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=10` in the `DataLoader` to improve performance.\n",
      "\n",
      "/Users/antoineedy/Documents/Formation/mail-project/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:78: UserWarning:\n",
      "\n",
      "Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 8. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "\n",
      "/Users/antoineedy/Documents/Formation/mail-project/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: PossibleUserWarning:\n",
      "\n",
      "The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=10` in the `DataLoader` to improve performance.\n",
      "\n",
      "/Users/antoineedy/Documents/Formation/mail-project/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:298: PossibleUserWarning:\n",
      "\n",
      "The number of training batches (12) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e685723858b24ebea9010d4e6c3aa849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "116da65c13bf453c970272fdd019f187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antoineedy/Documents/Formation/mail-project/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:78: UserWarning:\n",
      "\n",
      "Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 4. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dc185eff958423c89f5283159411ef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "782742085c87442787ffb59e93151c47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70dce4ba086d4731aa3384126266797b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc5f6514ff2447ea8655a99c46ddf038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "camembert_trainer.fit(lightning_model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lightning_model = LightningModel.load_from_checkpoint(checkpoint_path=model_checkpoint.best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'activite', 1: 'disponibilite_chambre', 2: 'ouverture_accueil'} {'activite': 0, 'disponibilite_chambre': 1, 'ouverture_accueil': 2}\n"
     ]
    }
   ],
   "source": [
    "ID_TO_LABEL = pd_dataset_train[\"label\"].unique()\n",
    "ID_TO_LABEL = {i: label for i, label in enumerate(ID_TO_LABEL)}\n",
    "\n",
    "LABEL_TO_ID = {label: i for i, label in ID_TO_LABEL.items()}\n",
    "\n",
    "print(ID_TO_LABEL, LABEL_TO_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds(model, tokenizer, sentence):\n",
    "    tokenized_sentence = tokenizer(sentence, return_tensors=\"pt\")\n",
    "    input_ids, attention_mask = tokenized_sentence.input_ids, tokenized_sentence.attention_mask\n",
    "\n",
    "    out = model(\n",
    "        input_ids=tokenized_sentence.input_ids,\n",
    "        attention_mask=tokenized_sentence.attention_mask\n",
    "    )\n",
    "\n",
    "    logits = out.logits\n",
    "\n",
    "    probas = torch.softmax(logits, -1).squeeze()\n",
    "\n",
    "    pred = torch.argmax(probas)\n",
    "\n",
    "    return ID_TO_LABEL[int(pred)], probas[pred].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: activite, confidence: 0.61\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"tu veux quoi toi\"\n",
    "\n",
    "label_predicted, proba = get_preds(lightning_model.model, tokenizer, test_sentence)\n",
    "\n",
    "print(f\"Label: {label_predicted}, confidence: {proba:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: activite, confidence: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sz/478g5qhx2d97xr1qbw_6tzqh0000gn/T/ipykernel_39895/1751575461.py:7: FutureWarning:\n",
      "\n",
      "You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "\n",
    "torch.save(lightning_model.model, 'model.pth')\n",
    "\n",
    "# load the model\n",
    "\n",
    "model = torch.load('model.pth')\n",
    "\n",
    "label_predicted, proba = get_preds(model, tokenizer, test_sentence)\n",
    "\n",
    "print(f\"Label: {label_predicted}, confidence: {proba:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mail-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U langchain-nomic langchain_community tiktoken langchainhub chromadb langchain langgraph nomic[local]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 49 mails (question+réponse) dans la base de données\n",
      "Il y a 30 actis dans la base de données\n",
      "Il y a 52 semaines de dispos renseignées pour les chambres dans la base de données\n",
      "Il y a 7 informations à propos de l'accueil dans la base de données\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "\n",
    "try:\n",
    "    with  open('data/mails.json', 'r') as f:\n",
    "        email_database = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError('mails.json not found')\n",
    "\n",
    "print(f\"Il y a {len(email_database)} mails (question+réponse) dans la base de données\")\n",
    "\n",
    "try :\n",
    "    actis = pd.read_csv('data/actis.csv')\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError('actis.csv not found')\n",
    "\n",
    "print(f\"Il y a {len(actis)} actis dans la base de données\")\n",
    "\n",
    "try :\n",
    "    chambres = pd.read_csv('data/chambres.csv')\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError('chambres.csv not found')\n",
    "\n",
    "print(f\"Il y a {len(chambres)} semaines de dispos renseignées pour les chambres dans la base de données\")\n",
    "\n",
    "try :\n",
    "    accueil = pd.read_csv('data/accueil.csv')\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError('accueil.csv not found')\n",
    "\n",
    "print(f\"Il y a {len(accueil)} informations à propos de l'accueil dans la base de données\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_llm = \"llama3.1\"\n",
    "local_embedder = \"nomic-embed-text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.embeddings import OllamaEmbeddings\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "embedder = OllamaEmbeddings(model = local_embedder)\n",
    "llm = ChatOllama(model = local_llm, temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose where to fecth the information from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama_instructor.ollama_instructor_client import OllamaInstructorClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2023, 2, 19, 0, 0)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2023-02-19\n",
    "datetime.strptime(\"2023-02-19\", \"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "## gérer les mails\n",
    "\n",
    "def try_content_from_mail(mail):\n",
    "    from langchain_core.documents import Document\n",
    "    with  open('data/mails.json', 'r') as f:\n",
    "            email_database = json.load(f)\n",
    "\n",
    "    full_text = []\n",
    "    for i, page in enumerate(email_database):\n",
    "        question = page['question']\n",
    "        answer = page['answer']\n",
    "        document = Document(\n",
    "            page_content=f\" QUESTION:\\n {question}\\n\\n ANSWER:\\n {answer}\",\n",
    "        )\n",
    "        full_text.append(document)\n",
    "\n",
    "    from langchain_chroma import Chroma\n",
    "    embedder = OllamaEmbeddings(model = local_embedder)\n",
    "\n",
    "    vectorstore = Chroma()\n",
    "    vectorstore.delete_collection()\n",
    "    vectorstore = Chroma.from_documents(documents=full_text, \n",
    "                                        embedding=embedder)\n",
    "    retriever = vectorstore.as_retriever()\n",
    "\n",
    "    TEMPLATE = \"\"\"Tu es un assistant qui va m'aider à répondre à des mails. J'ai déjà une base énorme de mails avec des questons et de réponses, et je veux que tu m'aides à répondre à des questions.\n",
    "    Je vaius te donner en contexte une paire question/réponse parmi mes mails, puis une question. Tu devras me donner la réponse qui correspond le mieux à la question. Tu peux dire \"je ne sais pas\" si tu ne sais pas.\n",
    "\n",
    "    Voici un exemple de question et de réponse :\n",
    "    {context}\n",
    "\n",
    "    Voici la question à laquelle tu dois répondre:\n",
    "    {question}\n",
    "\n",
    "    Tu vas UNIQUEMENT me donner la réponse à donner à la question. Tu n'as pas besoin de me donner la question, je la connais déjà.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(TEMPLATE)\n",
    "    rag_chain = (\n",
    "        {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "    )\n",
    "\n",
    "    res = rag_chain.invoke(mail)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RouteQuery(BaseModel):\n",
    "    \"\"\"Route a user query to the most relevant datasource.\"\"\"\n",
    "\n",
    "    datasource: Literal[\"disponibilite_chambres\", \"ouverture_accueil\", \"activite\", \"other\"] = Field(\n",
    "        ...,\n",
    "        description=\"Given a user question choose which datasource would be most relevant for answering their question. disponibilite_chambres refers to room availability, ouverture_accueil refers to the opening hours of the reception, activites refers to the prices of activities, other refers to a question that does not fit into any of the other categories.\",\n",
    "    )\n",
    "\n",
    "class RoomDates(BaseModel):\n",
    "    \"\"\"Gives the start and end dates of a room reservation that a user is asking about, in 2023, as well as the type of room.\"\"\"\n",
    "\n",
    "    start_date: str = Field(\n",
    "        ...,\n",
    "        description=\"The start date of the room reservation that the user is asking about.\",\n",
    "    )\n",
    "    end_date: str = Field(\n",
    "        ...,\n",
    "        description=\"The end date of the room reservation that the user is asking about.\",\n",
    "    )\n",
    "    room_type: Literal[\"double\", \"family\", \"not_specified\"] = Field(\n",
    "        ...,\n",
    "        description=\"The type of room that the user is asking about.\"\n",
    "    )\n",
    "\n",
    "client = OllamaInstructorClient()\n",
    "\n",
    "def dispo_chambre(mail: str) -> RoomDates:\n",
    "    response = client.chat_completion(\n",
    "        model='llama3.1', \n",
    "        pydantic_model=RoomDates, \n",
    "        messages=[\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': mail\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    start_date = response[\"message\"][\"content\"][\"start_date\"]\n",
    "    end_date = response[\"message\"][\"content\"][\"end_date\"]\n",
    "    room_type = response[\"message\"][\"content\"][\"room_type\"]\n",
    "\n",
    "    start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "    end_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "\n",
    "    data = pd.read_csv('data/chambres.csv')\n",
    "\n",
    "    week_beg = None\n",
    "    week_end = None\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        if datetime.strptime(row['Date_Debut'], \"%Y-%m-%d\") >= start_date and week_beg is None:\n",
    "            week_beg = index - 1\n",
    "        if datetime.strptime(row['Date_Fin'], \"%Y-%m-%d\") >= end_date:\n",
    "            week_end = index\n",
    "        if week_beg is not None and week_end is not None:\n",
    "            break    \n",
    "    \n",
    "    if week_beg is None or week_end is None:\n",
    "        raise Exception(\"No data found for this period\")\n",
    "\n",
    "    data = data.iloc[week_beg:week_end]\n",
    "    return {\"start_date\": start_date, \"end_date\": end_date, \"room_type\": room_type, \"data\": data}\n",
    "\n",
    "def choose_route(mail: str) -> RouteQuery:\n",
    "    response = client.chat_completion(\n",
    "        model='llama3.1', \n",
    "        pydantic_model=RouteQuery, \n",
    "        messages=[\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': mail\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return {\"question\": mail, \"datasource\": response[\"message\"][\"content\"]['datasource']}\n",
    "\n",
    "def continue_root(state):\n",
    "    question = state[\"question\"]\n",
    "    datasource = state[\"datasource\"]\n",
    "    print('-----------------')\n",
    "    print(f\"Question : {question}\")\n",
    "    print(f\"Datasource : {datasource}\")\n",
    "    print('-----------------')\n",
    "    if datasource == \"ouverture_accueil\":\n",
    "        data = pd.read_csv('data/accueil.csv')\n",
    "        PROMPT = f\"\"\"Tu es un assistant va répondre à une question de l'utilisateur à propos des horaires d'ouverture de l'accueil. Tu vas être très simple et factuel. Tu vas t'exprimer clairement.\n",
    "\n",
    "        Question : {question}\n",
    "\n",
    "        \n",
    "        Tu vas répondre à l'aide de ces données:\n",
    "        Données :\n",
    "        \"\"\" + data.to_string()\n",
    "        return PROMPT\n",
    "    \n",
    "    elif datasource == \"disponibilite_chambres\":\n",
    "        out = dispo_chambre(question)\n",
    "        PROMPT = f\"\"\"Tu es un assistant va répondre à une question de l'utilisateur à propos de la disponibilité des chambres. Tu vas être très simple et factuel. Tu vas t'exprimer clairement.\n",
    "\n",
    "        Question : {question}\n",
    "\n",
    "        Tu vas prendre en compte la période suivante : {out[\"start_date\"]} - {out[\"end_date\"]} pour une chambre de type {out[\"room_type\"]}.\n",
    "\n",
    "        Tu vas répondre à l'aide de ces données:\n",
    "        Données :\n",
    "        \"\"\" + out[\"data\"].to_string()\n",
    "        return PROMPT\n",
    "    \n",
    "    elif datasource == \"activite\":\n",
    "        data = pd.read_csv('data/actis.csv')\n",
    "        PROMPT = f\"\"\"Tu es un assistant va répondre à une question de l'utilisateur à propos des prix des activités. Tu vas être très simple et factuel. Tu vas t'exprimer clairement.\n",
    "\n",
    "        Question : {question}\n",
    "\n",
    "        Tu vas répondre à l'aide de ces données.\n",
    "        Données :\n",
    "        \"\"\" + data.to_string()\n",
    "        return PROMPT\n",
    "    \n",
    "    elif datasource == \"other\":\n",
    "        return try_content_from_mail(question)\n",
    "        \n",
    "\n",
    "chain = RunnableLambda(choose_route) | RunnableLambda(continue_root) | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mail = \"Je veux venir mardi à 13h à l'accueil, est-ce que c'est possible ?\"\n",
    "#print(chain.invoke(mail))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mail = \"Je veux venir le 15 aout avec ma famille pour une semaine, est-ce que vous avez des chambres disponibles ?\"\n",
    "#print(chain.invoke(mail))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mail = \"Est-ce que vous avez une activitée de soin du visage ?\"\n",
    "#print(chain.invoke(mail))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "Question : Avez-vous une piscine ?\n",
      "Datasource : other\n",
      "-----------------\n",
      "Oui, nous avons une piscine sur place.\n"
     ]
    }
   ],
   "source": [
    "mail = \"Avez-vous une piscine ?\"\n",
    "print(chain.invoke(mail))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mail-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
